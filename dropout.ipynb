{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2e6a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/allen/miniconda3\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 458ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m     0 B/34.43 KiB                     \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[0m\u001b[0m 16.00 KiB/34.43 KiB                   \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)2m--\u001b[0m\u001b[0m 32.00 KiB/34.43 KiB                   \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 150ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 14ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabulate\u001b[0m\u001b[2m==0.9.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588f5d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "DEVICE = torch.device(f'cuda:{torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999cfef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _dropout(\n",
    "    x_ptr,\n",
    "    x_keep_ptr,\n",
    "    output_ptr,\n",
    "    n_elements,\n",
    "    p,\n",
    "    BLOCK_SIZE: tl.constexpr\n",
    "):\n",
    "    PID = tl.program_id(axis=0)\n",
    "    block_start = PID * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < n_elements\n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    x_keep = tl.load(x_keep_ptr + offsets, mask=mask)\n",
    "    output = tl.where(x_keep, x / (1-p), 0.0)\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de02d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(x, x_keep, p):\n",
    "    output = torch.empty_like(x)\n",
    "    assert x.is_contiguous()\n",
    "    n_elements = x.numel()\n",
    "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
    "    _dropout[grid](x, x_keep, output, n_elements, p, BLOCK_SIZE=1024)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043cec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 1, 0, 1, 0, 0, 0], device='cuda:0', dtype=torch.int32)\n",
      "---------  -------  --------  -------  --------  -------  --------  ----------  --------  -------  -------\n",
      "input      -1.8765  -1.47489  -0.7433  -1.74919  2.126    -1.70117  -0.0978969  0.477327  1.08858  -1.2364\n",
      "keep mask   0        1         0        0        1         0         1          0         0         0\n",
      "output      0       -2.94979   0        0        4.25201   0        -0.195794   0         0         0\n",
      "---------  -------  --------  -------  --------  -------  --------  ----------  --------  -------  -------\n"
     ]
    }
   ],
   "source": [
    "import tabulate\n",
    "\n",
    "x = torch.randn(size=(10,), device=DEVICE)\n",
    "p = 0.5\n",
    "x_keep = (torch.randn(size=(10,), device=DEVICE) > p).to(torch.int32)\n",
    "# print(x_keep)\n",
    "\n",
    "output = dropout(x, x_keep=x_keep, p=p)\n",
    "print(tabulate.tabulate([\n",
    "    [\"input\"] + x.tolist(),\n",
    "    [\"keep mask\"] + x_keep.tolist(),\n",
    "    [\"output\"] + output.tolist(),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cef31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _seeded_dropout(\n",
    "    x_ptr,\n",
    "    output_ptr,\n",
    "    n_elements,\n",
    "    p,    # float32 [0,1]\n",
    "    seed, # int32\n",
    "    BLOCK_SIZE: tl.constexpr,\n",
    "):\n",
    "    PID = tl.program_id(axis=0)\n",
    "    block_start = PID * BLOCK_SIZE\n",
    "    offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
    "    mask = offsets < n_elements\n",
    "    x = tl.load(x_ptr + offsets, mask=mask)\n",
    "    x_keep = tl.rand(seed, offsets) > p\n",
    "    output = tl.where(x_keep, x / (1-p), 0.0)\n",
    "    tl.store(output_ptr + offsets, output, mask=mask)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77c34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeded_dropout(x, p, seed):\n",
    "    output = torch.empty_like(x)\n",
    "    assert x.is_contiguous()\n",
    "    n_elements = x.numel()\n",
    "    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
    "    _seeded_dropout[grid](x, output, n_elements, p, seed, BLOCK_SIZE=1024)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11201429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------  ---------  -------  --------  ------------  -------  ---------  --------  --------  --------  ---------\n",
      "input                -0.103223  1.48454  -1.93938  -0.000645571  1.17313  -0.079865  -1.35829  -0.50152  -1.40758  -0.724626\n",
      "output (seed = 123)   0         2.96907   0         0            0        -0.15973    0         0        -2.81516  -1.44925\n",
      "output (seed = 123)   0         2.96907   0         0            0        -0.15973    0         0        -2.81516  -1.44925\n",
      "output (seed = 512)   0         0        -3.87876  -0.00129114   0        -0.15973   -2.71659   0         0         0\n",
      "-------------------  ---------  -------  --------  ------------  -------  ---------  --------  --------  --------  ---------\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=(10, ), device=DEVICE)\n",
    "# Compare this to the baseline - dropout mask is never instantiated!\n",
    "output = seeded_dropout(x, p=0.5, seed=123)\n",
    "output2 = seeded_dropout(x, p=0.5, seed=123)\n",
    "output3 = seeded_dropout(x, p=0.5, seed=512)\n",
    "\n",
    "print(\n",
    "    tabulate.tabulate([\n",
    "        [\"input\"] + x.tolist(),\n",
    "        [\"output (seed = 123)\"] + output.tolist(),\n",
    "        [\"output (seed = 123)\"] + output2.tolist(),\n",
    "        [\"output (seed = 512)\"] + output3.tolist(),\n",
    "    ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

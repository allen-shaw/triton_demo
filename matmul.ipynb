{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ac5701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import triton \n",
    "import triton.language as tl\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46e3a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "autotune_configs = [\n",
    "    # triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE': 8}, num_stages=3, num_warps=8),\n",
    "    # triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE': 8}, num_stages=4, num_warps=4),\n",
    "    triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE': 8}, num_stages=4, num_warps=4),\n",
    "    # triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE': 8}, num_stages=4, num_warps=4),\n",
    "    # triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE': 8}, num_stages=4, num_warps=4),\n",
    "    # triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE': 8}, num_stages=4, num_warps=4),\n",
    "    # triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE': 8}, num_stages=5, num_warps=2),\n",
    "    # triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE': 8}, num_stages=5, num_warps=2)\n",
    "]\n",
    "\n",
    "@triton.autotune(configs=autotune_configs, key=['M','N','K'])\n",
    "@triton.jit\n",
    "def _matmul_kernel(\n",
    "    a_ptr, b_ptr, c_ptr,\n",
    "    M, N, K,\n",
    "    stride_a_M, stride_a_K,\n",
    "    stride_b_K, stride_b_N,\n",
    "    stride_c_M, stride_c_N,\n",
    "    BLOCK_SIZE_M: tl.constexpr,\n",
    "    BLOCK_SIZE_N: tl.constexpr,\n",
    "    BLOCK_SIZE_K: tl.constexpr,\n",
    "    GROUP_SIZE: tl.constexpr,  # how many block line in a group\n",
    "):\n",
    "    PID = tl.program_id(axis=0)\n",
    "    block_num_M = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    block_num_N = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    block_num_in_group = GROUP_SIZE * block_num_N\n",
    "\n",
    "    group_id = PID // block_num_in_group\n",
    "    first_block_id_in_group_M = group_id * GROUP_SIZE\n",
    "\n",
    "    group_size = min(block_num_M - first_block_id_in_group_M, GROUP_SIZE)\n",
    "    \n",
    "    block_id_M = first_block_id_in_group_M + ((PID % block_num_in_group) % group_size)\n",
    "    block_id_N = (PID % block_num_in_group) // group_size\n",
    "\n",
    "    offsets_M = block_id_M * BLOCK_SIZE_M + tl.arange(0, BLOCK_SIZE_M)\n",
    "    offsets_N = block_id_N * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)\n",
    "    offsets_K = tl.arange(0, BLOCK_SIZE_K)\n",
    "\n",
    "    a_offsets = offsets_M[:, None] * stride_a_M + offsets_K[None, :] * stride_a_K\n",
    "    b_offsets = offsets_K[:, None] * stride_b_K + offsets_N[None, :] * stride_b_N\n",
    "\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "\n",
    "    for k in range(0, tl.cdiv(K, BLOCK_SIZE_K)):\n",
    "        mask = k * BLOCK_SIZE_K + offsets_K < K\n",
    "        a = tl.load(a_ptr + a_offsets, mask=mask[None, :], other=0.0)\n",
    "        b = tl.load(b_ptr + b_offsets, mask=mask[:, None], other=0.0)\n",
    "\n",
    "        accumulator = tl.dot(a, b, acc=accumulator)\n",
    "        a_offsets += BLOCK_SIZE_K * stride_a_K\n",
    "        b_offsets += BLOCK_SIZE_K * stride_b_K\n",
    "    \n",
    "    c_offsets = stride_c_M * offsets_M[:, None] + stride_c_N * offsets_N[None, :]\n",
    "    c_mask = (offsets_M[:, None] < M) & (offsets_N[None,:] < N)\n",
    "    tl.store(c_ptr + c_offsets, accumulator.to(tl.float16), mask=c_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c8ef3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a: torch.Tensor, b: torch.Tensor):\n",
    "    assert a.ndim == b.ndim == 2\n",
    "    assert a.shape[1] == b.shape[0]\n",
    "\n",
    "    (M, K), (_, N) = a.shape, b.shape\n",
    "\n",
    "    c = torch.empty((M, N), device=DEVICE, dtype=torch.float16)\n",
    "    '''\n",
    "    [0, 1]\n",
    "    [2, 3]\n",
    "    '''\n",
    "    grid = lambda meta: (\n",
    "        triton.cdiv(M, meta['BLOCK_SIZE_M']) * triton.cdiv(N, meta['BLOCK_SIZE_N']),\n",
    "    )\n",
    "    _matmul_kernel[grid](\n",
    "        a, b, c,\n",
    "        M, N, K,\n",
    "        a.stride(0), a.stride(1),\n",
    "        b.stride(0), b.stride(1),\n",
    "        c.stride(0), c.stride(1),\n",
    "    )\n",
    "    return c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b80998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matmul_kernel(size1, size2: tuple, atol=1e-2, rtol=1e-1, device=DEVICE):\n",
    "    torch.manual_seed(0)\n",
    "    assert type(size1) == tuple and len(size1) == 2\n",
    "    assert type(size2) == tuple and len(size2) == 2\n",
    "    assert size1[1] == size2[0]\n",
    "\n",
    "    a = torch.randn(size1, device=DEVICE, dtype=torch.float16)\n",
    "    b = torch.randn(size2, device=DEVICE, dtype=torch.float16)\n",
    "\n",
    "    c_tri = matmul(a, b)\n",
    "    c_ref = torch.matmul(a, b)\n",
    "\n",
    "    torch.testing.assert_close(c_tri, c_ref, atol=atol, rtol=rtol)\n",
    "    print('PASSED')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acb9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "test_matmul_kernel(size1=(1024, 512),size2=(512, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "021698e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    triton.testing.Benchmark(\n",
    "        x_names = [\"M\", \"N\", \"K\"], # we can increase multiple dimensions simultaneously while benchmarking\n",
    "        x_vals = [128 * i for i in range(2, 33)],\n",
    "        line_arg = \"provider\", \n",
    "        line_vals = [\"torch\", \"triton\"],\n",
    "        line_names = [\"PyTorch\", \"Triton\"],\n",
    "        styles = [(\"green\", \"-\"), (\"blue\", \"-\")],\n",
    "        ylabel = \"TFLOPS\", \n",
    "        plot_name = \"matmul-performance\",\n",
    "        args={},\n",
    "    )\n",
    "]\n",
    "@triton.testing.perf_report(configs)\n",
    "def benchmark(M, N, K, provider):\n",
    "    a = torch.randn((M, K), device=DEVICE, dtype=torch.float16)\n",
    "    b = torch.randn((K, N), device=DEVICE, dtype=torch.float16)\n",
    "    quantiles = [0.5, 0.05, 0.95]\n",
    "    if provider == 'torch':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: torch.matmul(a, b), quantiles=quantiles)\n",
    "    if provider == 'triton':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: matmul(a, b), quantiles=quantiles)\n",
    "    perf = lambda ms: 3 * M * N * K * 1e-12 / (ms * 1e-3)\n",
    "        # 3 = number of memory operations (2 read + 1 write)\n",
    "        # M * N * K = number of elements per memory op\n",
    "        # 1e-12 converts flops to Teraflops\n",
    "        # 1e-3 converts milliseconds to seconds\n",
    "    return perf(ms), perf(max_ms), perf(min_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.run(print_data=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
